{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:06.871678Z",
     "start_time": "2024-06-23T15:11:05.156170Z"
    }
   },
   "outputs": [],
   "source": [
    "from haystack.telemetry import tutorial_running\n",
    "\n",
    "tutorial_running(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initializing the DocumentStore\n",
    "- to store data in memory (good for smaller project, for larger project use qdrant/weaviate etc vector db)\n",
    "- indexing the data with its embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "827c1cddabc425c2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:06.878715Z",
     "start_time": "2024-06-23T15:11:06.872851Z"
    }
   },
   "id": "dde164a133df25f1",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Adding documents/dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e8f952ba7148192"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split='train')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:13.012893Z",
     "start_time": "2024-06-23T15:11:06.879641Z"
    }
   },
   "id": "fceeabb24d850a64",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'b3de1a673c1eb2876585405395a10c3d',\n 'content': 'The Colossus of Rhodes (Ancient Greek: ὁ Κολοσσὸς Ῥόδιος, romanized:\\xa0ho Kolossòs Rhódios Greek: Κολοσσός της Ρόδου, romanized:\\xa0Kolossós tes Rhódou)[a] was a statue of the Greek sun-god Helios, erected in the city of Rhodes, on the Greek island of the same name, by Chares of Lindos in 280\\xa0BC. One of the Seven Wonders of the Ancient World, it was constructed to celebrate the successful defence of Rhodes city against an attack by Demetrius Poliorcetes, who had besieged it for a year with a large army and navy.\\nAccording to most contemporary descriptions, the Colossus stood approximately 70 cubits, or 33 metres (108 feet) high – approximately the height of the modern Statue of Liberty from feet to crown – making it the tallest statue in the ancient world.[2] It collapsed during the earthquake of 226 BC, although parts of it were preserved. In accordance with a certain oracle, the Rhodians did not build it again.[3] John Malalas wrote that Hadrian in his reign re-erected the Colossus,[4] but he was mistaken.[5] According to the Suda, the Rhodians were called Colossaeans (Κολοσσαεῖς), because they erected the statue on the island.',\n 'content_type': 'text',\n 'meta': {'url': 'https://en.wikipedia.org/wiki/Colossus_of_Rhodes',\n  '_split_id': 0},\n 'id_hash_keys': ['content'],\n 'score': None,\n 'embedding': None}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:13.018558Z",
     "start_time": "2024-06-23T15:11:13.013970Z"
    }
   },
   "id": "93fd115f1526414c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from haystack import Document \n",
    "\n",
    "docs = [Document(content=doc['content'], meta=doc['meta']) for doc in dataset]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:13.073086Z",
     "start_time": "2024-06-23T15:11:13.019208Z"
    }
   },
   "id": "a360156e8f1efd8a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Document(id=75fd8474f2c88337f7e0dad69eba0f24ba293cb06693fb746ec403df01a1c0c5, content: 'The Colossus of Rhodes (Ancient Greek: ὁ Κολοσσὸς Ῥόδιος, romanized: ho Kolossòs Rhódios Greek: Κολο...', meta: {'url': 'https://en.wikipedia.org/wiki/Colossus_of_Rhodes', '_split_id': 0})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:13.081277Z",
     "start_time": "2024-06-23T15:11:13.073884Z"
    }
   },
   "id": "21cb988ad5b15b49",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initialize a Document Embedder\n",
    "- To create embeddings of the document"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82d5a461f57b9b82"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sibxy/anaconda3/envs/pyTorch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder as STDocEmb\n",
    "\n",
    "doc_embedder = STDocEmb(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Downloading the mdoel\n",
    "doc_embedder.warm_up()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:16.544648Z",
     "start_time": "2024-06-23T15:11:13.082240Z"
    }
   },
   "id": "ca7848cae04c3cce",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Embedding documents"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f1a0f800768d788"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11ee8de2c55c4dec878f75cd6783de8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "151"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write document to the document store\n",
    "\n",
    "embedded_docs = doc_embedder.run(docs)\n",
    "document_store.write_documents(embedded_docs['documents'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:17.014757Z",
     "start_time": "2024-06-23T15:11:16.545813Z"
    }
   },
   "id": "f5c09d8846562e93",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Text Embedder for Queries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "705a38f9ac6a4c43"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder as STTextEmb\n",
    "\n",
    "text_embedder = STTextEmb(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:17.018320Z",
     "start_time": "2024-06-23T15:11:17.015724Z"
    }
   },
   "id": "5edff0757a37dd9a",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initialize Retriever"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a78c3063065e5a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:17.029099Z",
     "start_time": "2024-06-23T15:11:17.019863Z"
    }
   },
   "id": "907fa83ecee85d8a",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define a Template Prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f89a60f68cb8d309"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context: \n",
    "{% for doc in documents %}\n",
    "    {{doc.content}}\n",
    "{% endfor %}\n",
    "\n",
    "question: {{query}}\n",
    "answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:17.040328Z",
     "start_time": "2024-06-23T15:11:17.030099Z"
    }
   },
   "id": "14b97da6af833876",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:17.043006Z",
     "start_time": "2024-06-23T15:11:17.041316Z"
    }
   },
   "id": "e8d2d1df79559bc7",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdotenv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomponents\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HuggingFaceAPIGenerator\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HfApi\n\u001B[1;32m     10\u001B[0m load_dotenv()\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/haystack/components/generators/__init__.py:9\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomponents\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mopenai\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa: I001 (otherwise we end up with partial imports)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     OpenAIGenerator,\n\u001B[1;32m      7\u001B[0m )\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomponents\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mazure\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AzureOpenAIGenerator\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomponents\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhugging_face_local\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HuggingFaceLocalGenerator\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomponents\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhugging_face_tgi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HuggingFaceTGIGenerator\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomponents\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhugging_face_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HuggingFaceAPIGenerator\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/haystack/components/generators/hugging_face_local.py:24\u001B[0m\n\u001B[1;32m     21\u001B[0m SUPPORTED_TASKS \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext2text-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m LazyImport(message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpip install transformers[torch]\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m transformers_import:\n\u001B[0;32m---> 24\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StoppingCriteriaList, pipeline\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhaystack\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# pylint: disable=ungrouped-imports\u001B[39;00m\n\u001B[1;32m     27\u001B[0m         HFTokenStreamingHandler,\n\u001B[1;32m     28\u001B[0m         StopWordsCriteria,\n\u001B[1;32m     29\u001B[0m         resolve_hf_pipeline_kwargs,\n\u001B[1;32m     30\u001B[0m     )\n\u001B[1;32m     33\u001B[0m \u001B[38;5;129m@component\u001B[39m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mHuggingFaceLocalGenerator\u001B[39;00m:\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1412\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[0;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/transformers/utils/import_utils.py:1525\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1523\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m-> 1525\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1526\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[1;32m   1527\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/transformers/utils/import_utils.py:1535\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[0;34m(self, module_name)\u001B[0m\n\u001B[1;32m   1533\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_module\u001B[39m(\u001B[38;5;28mself\u001B[39m, module_name: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m   1534\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1535\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1536\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1537\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1538\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1539\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1540\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/importlib/__init__.py:90\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m     88\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     89\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/transformers/pipelines/__init__.py:47\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtokenization_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PreTrainedTokenizer\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     34\u001B[0m     CONFIG_NAME,\n\u001B[1;32m     35\u001B[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     45\u001B[0m     logging,\n\u001B[1;32m     46\u001B[0m )\n\u001B[0;32m---> 47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio_classification\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AudioClassificationPipeline\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautomatic_speech_recognition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutomaticSpeechRecognitionPipeline\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     50\u001B[0m     ArgumentHandler,\n\u001B[1;32m     51\u001B[0m     CsvPipelineDataFormat,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     59\u001B[0m     infer_framework_load_model,\n\u001B[1;32m     60\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/transformers/pipelines/audio_classification.py:21\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m add_end_docstrings, is_torch_available, is_torchaudio_available, logging\n\u001B[0;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pipeline, build_pipeline_init_args\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_auto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/transformers/pipelines/base.py:34\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_extraction_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PreTrainedFeatureExtractor\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage_processing_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseImageProcessor\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodelcard\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelCard\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfiguration_auto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoConfig\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtokenization_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PreTrainedTokenizer\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/transformers/modelcard.py:48\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_auto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     33\u001B[0m     MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES,\n\u001B[1;32m     34\u001B[0m     MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     46\u001B[0m     MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001B[1;32m     47\u001B[0m )\n\u001B[0;32m---> 48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining_args\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ParallelMode\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     50\u001B[0m     MODEL_CARD_NAME,\n\u001B[1;32m     51\u001B[0m     cached_file,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m     logging,\n\u001B[1;32m     58\u001B[0m )\n\u001B[1;32m     61\u001B[0m TASK_MAPPING \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m: MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage-classification\u001B[39m\u001B[38;5;124m\"\u001B[39m: MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzero-shot-image-classification\u001B[39m\u001B[38;5;124m\"\u001B[39m: MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001B[1;32m     75\u001B[0m }\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/transformers/training_args.py:208\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m passed_value\n\u001B[1;32m    207\u001B[0m \u001B[38;5;66;03m# TODO: `TrainingArguments` users rely on it being fully mutable. In the future see if we can narrow this to a few keys: https://github.com/huggingface/transformers/pull/25903\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m \u001B[38;5;129;43m@dataclass\u001B[39;49m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;21;43;01mTrainingArguments\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;250;43m    \u001B[39;49m\u001B[38;5;124;43;03m\"\"\"\u001B[39;49;00m\n\u001B[1;32m    211\u001B[0m \u001B[38;5;124;43;03m    TrainingArguments is the subset of the arguments we use in our example scripts **which relate to the training loop\u001B[39;49;00m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;124;43;03m    itself**.\u001B[39;49;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;124;43;03m            summary statistics from the batch-level summary statistics you've accumulated over the evaluation set.\u001B[39;49;00m\n\u001B[1;32m    765\u001B[0m \u001B[38;5;124;43;03m    \"\"\"\u001B[39;49;00m\n\u001B[1;32m    767\u001B[0m \u001B[43m    \u001B[49m\u001B[43mframework\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/dataclasses.py:1275\u001B[0m, in \u001B[0;36mdataclass\u001B[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001B[0m\n\u001B[1;32m   1272\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m wrap\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;66;03m# We're called as @dataclass without parens.\u001B[39;00m\n\u001B[0;32m-> 1275\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/dataclasses.py:1265\u001B[0m, in \u001B[0;36mdataclass.<locals>.wrap\u001B[0;34m(cls)\u001B[0m\n\u001B[1;32m   1264\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrap\u001B[39m(\u001B[38;5;28mcls\u001B[39m):\n\u001B[0;32m-> 1265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_process_class\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mrepr\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munsafe_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mfrozen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmatch_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkw_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mslots\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1267\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mweakref_slot\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/dataclasses.py:1092\u001B[0m, in \u001B[0;36m_process_class\u001B[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001B[0m\n\u001B[1;32m   1089\u001B[0m     self_tuple \u001B[38;5;241m=\u001B[39m _tuple_str(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m'\u001B[39m, flds)\n\u001B[1;32m   1090\u001B[0m     other_tuple \u001B[38;5;241m=\u001B[39m _tuple_str(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mother\u001B[39m\u001B[38;5;124m'\u001B[39m, flds)\n\u001B[1;32m   1091\u001B[0m     _set_new_attribute(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__eq__\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m-> 1092\u001B[0m                        \u001B[43m_cmp_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m__eq__\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m==\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1093\u001B[0m \u001B[43m                               \u001B[49m\u001B[43mself_tuple\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1094\u001B[0m \u001B[43m                               \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1096\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m order:\n\u001B[1;32m   1097\u001B[0m     \u001B[38;5;66;03m# Create and set the ordering methods.\u001B[39;00m\n\u001B[1;32m   1098\u001B[0m     flds \u001B[38;5;241m=\u001B[39m [f \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m field_list \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mcompare]\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/dataclasses.py:667\u001B[0m, in \u001B[0;36m_cmp_fn\u001B[0;34m(name, op, self_tuple, other_tuple, globals)\u001B[0m\n\u001B[1;32m    661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cmp_fn\u001B[39m(name, op, self_tuple, other_tuple, \u001B[38;5;28mglobals\u001B[39m):\n\u001B[1;32m    662\u001B[0m     \u001B[38;5;66;03m# Create a comparison function.  If the fields in the object are\u001B[39;00m\n\u001B[1;32m    663\u001B[0m     \u001B[38;5;66;03m# named 'x' and 'y', then self_tuple is the string\u001B[39;00m\n\u001B[1;32m    664\u001B[0m     \u001B[38;5;66;03m# '(self.x,self.y)' and other_tuple is the string\u001B[39;00m\n\u001B[1;32m    665\u001B[0m     \u001B[38;5;66;03m# '(other.x,other.y)'.\u001B[39;00m\n\u001B[0;32m--> 667\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_create_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m                      \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mself\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mother\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m                      \u001B[49m\u001B[43m[\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mif other.__class__ is self.__class__:\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m                       \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m return \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mself_tuple\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mop\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mother_tuple\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m                        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mreturn NotImplemented\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/dataclasses.py:473\u001B[0m, in \u001B[0;36m_create_fn\u001B[0;34m(name, args, body, globals, locals, return_type)\u001B[0m\n\u001B[1;32m    471\u001B[0m txt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdef __create_fn__(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlocal_vars\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mtxt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m return \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    472\u001B[0m ns \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 473\u001B[0m \u001B[43mexec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtxt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ns[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__create_fn__\u001B[39m\u001B[38;5;124m'\u001B[39m](\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlocals\u001B[39m)\n",
      "File \u001B[0;32m<string>:0\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.utils import Secret\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hf_auth_key = os.environ.get(\"HF_KEY\") \n",
    "SERVER_LESS_API_KEY = \"https://api-inference.huggingface.co/models/google/gemma-2b-it\" \n",
    "\n",
    "print(hf_auth_key)\n",
    "\n",
    "pipe = Pipeline()\n",
    "generator = HuggingFaceAPIGenerator(api_type=\"serverless_inference_api\", api_params={\"model\": 'google/gemma-2b-it', 'url': SERVER_LESS_API_KEY}, token=Secret.from_token(hf_auth_key))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-27T16:28:33.771450Z"
    }
   },
   "id": "4578c4d92065e8c",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pipe.add_component('text_embedder', text_embedder)\n",
    "pipe.add_component(\"retriever\", retriever)\n",
    "pipe.add_component('prompt_builder', prompt_builder)\n",
    "pipe.add_component('llm', generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:17.335453Z",
     "start_time": "2024-06-23T15:11:17.332561Z"
    }
   },
   "id": "ee8905c987730d58",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f92d0f22790>\n🚅 Components\n  - text_embedder: SentenceTransformersTextEmbedder\n  - retriever: InMemoryEmbeddingRetriever\n  - prompt_builder: PromptBuilder\n  - llm: HuggingFaceAPIGenerator\n🛤️ Connections\n  - text_embedder.embedding -> retriever.query_embedding (List[float])\n  - retriever.documents -> prompt_builder.documents (List[Document])\n  - prompt_builder.prompt -> llm.prompt (str)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.connect('text_embedder.embedding', 'retriever.query_embedding')\n",
    "pipe.connect('retriever', 'prompt_builder.documents')\n",
    "pipe.connect('prompt_builder', 'llm')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:17.344406Z",
     "start_time": "2024-06-23T15:11:17.338904Z"
    }
   },
   "id": "6f1fd2623d2cb9b7",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd17c3edf2674c81870f0af79fc87773"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replies': [' The seven wonders of the world are:\\n\\n1. The Great Pyramid of Giza\\n2. The Hanging Gardens of Babylon\\n3. The Lighthouse of Alexandria\\n4. The Statue of Zeus by the Alpheus\\n5. The Colossus of Helius\\n6. The Hanging Gardens of Semiramis\\n7. The Mausoleum at Halicarnassus'], 'meta': [{'model': 'google/gemma-2b-it', 'finish_reason': 'eos_token', 'usage': {'completion_tokens': 74}}]}\n"
     ]
    }
   ],
   "source": [
    "output = pipe.run({\n",
    "    'text_embedder': {\n",
    "        'text': 'What are the seven wonders of the world?'\n",
    "    },\n",
    "    'prompt_builder': {\n",
    "        'query': 'What are the seven wonders of the world?'\n",
    "    }\n",
    "})\n",
    "\n",
    "\n",
    "print(output['llm'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:11:18.510262Z",
     "start_time": "2024-06-23T15:11:17.345114Z"
    }
   },
   "id": "cda66c0cceaa4919",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcdc1375eaa7452ea0d9467833085830"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replies': [' The statue of Zeus at Rhodes was a colossal statue of bronze and ivory, standing approximately 70 cubits (32 meters) high.'], 'meta': [{'model': 'google/gemma-2b-it', 'finish_reason': 'eos_token', 'usage': {'completion_tokens': 30}}]}\n"
     ]
    }
   ],
   "source": [
    "q2 = 'What does Rhodes Statue look like'\n",
    "output = pipe.run({\n",
    "    'text_embedder': {\n",
    "        'text': q2 \n",
    "    },\n",
    "    'prompt_builder': {\n",
    "        'query': q2 \n",
    "    }\n",
    "})\n",
    "\n",
    "\n",
    "print(output['llm'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:13:00.945750Z",
     "start_time": "2024-06-23T15:12:30.625513Z"
    }
   },
   "id": "d332356697e14ce1",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "73dbd7b03c1ba45d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
