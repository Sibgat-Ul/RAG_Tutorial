{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "### Loading tavily stuffs\n",
    "from langchain.tools.tavily_search import TavilySearchResults \n",
    "\n",
    "### Loading langchain stuffs\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "### some more shitty stuffs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # avoid warning messages importing packages\n",
    "\n",
    "import json\n",
    "\n",
    "REQUEST_PER_QUESTION = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:17.916693Z",
     "start_time": "2024-07-03T12:45:17.448747Z"
    }
   },
   "id": "f499cce6cc0f06f5",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Tavily API Key\n",
    "auth_key_tavily = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "# HuggingFace API Key\n",
    "auth_key_hf = os.environ.get(\"HF_KEY\")\n",
    "\n",
    "# Langchain key\n",
    "langchain_key = os.environ.get(\"LANGCHAIN_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:17.923471Z",
     "start_time": "2024-07-03T12:45:17.917878Z"
    }
   },
   "id": "d916759a5c24e1bc",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "# snapshot_download(repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir='./Mistral_7B_Instruct_v0.3/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:18.057539Z",
     "start_time": "2024-07-03T12:45:17.924113Z"
    }
   },
   "id": "691441f2e6348212",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7466f42734824fd285b024880a1addf0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain Machine Learning to me in a nutshell. Machine Learning (ML) is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.\n",
      "\n",
      "In simpler terms, it's like teaching a computer to recognize patterns and make decisions based on that learning. Here's a breakdown:\n",
      "\n",
      "1. Data Collection: Gather a large amount of data related to the problem you want to solve. For example, if you want to predict house prices, you'd need data about houses and their prices.\n",
      "\n",
      "2. Data Preparation: Clean and preprocess the data to make it suitable for learning\n"
     ]
    }
   ],
   "source": [
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.messages import UserMessage, AssistantMessage\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig, pipeline\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "mistral_models_path = './Mistral_7B_Instruct_v0.3/' \n",
    "\n",
    "tokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tokenizer.model.v3\")\n",
    "# model = Transformer.from_file({mistral_models_path})\n",
    "model = AutoModelForCausalLM.from_pretrained('mistralai/Mistral-7B-Instruct-v0.3', quantization_config=quantization_config)\n",
    "\n",
    "completion_request = ChatCompletionRequest(messages=[UserMessage(content=\"Explain Machine Learning to me in a nutshell.\")])\n",
    "tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
    "generated_ids = model.generate(torch.tensor([tokens]).to('cuda'), max_new_tokens=128)\n",
    "result = tokenizer.decode(generated_ids[0].tolist())\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:46.552158Z",
     "start_time": "2024-07-03T12:45:18.058420Z"
    }
   },
   "id": "1bcfe5623ad9b42f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "# ]\n",
    "# \n",
    "# encodeds = tokenizer_auto.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "# \n",
    "# generated_ids = model.generate(encodeds.to('cuda'), max_new_tokens=64, do_sample=True)\n",
    "# decoded = tokenizer_auto.batch_decode(generated_ids)\n",
    "# print(decoded[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:46.559328Z",
     "start_time": "2024-07-03T12:45:46.555319Z"
    }
   },
   "id": "a160e540bb86bb58",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_huggingface import (\n",
    "    HuggingFacePipeline, HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_auto = AutoTokenizer.from_pretrained('mistralai/Mistral-7B-Instruct-v0.3', max_length=128, skip_special_tokens=True)\n",
    "tokenizer_auto.pad_token = tokenizer_auto.eos_token\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer_auto, \n",
    "    do_sample=True, \n",
    "    max_new_tokens=128,\n",
    "    truncation='only_first',\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=pipe,\n",
    ")\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     endpoint_url = \"https://api-inference.huggingface.co/models/google/gemma-2b-it\",\n",
    "#     task='text-generation',\n",
    "#     max_new_tokens=64,\n",
    "#     top_k=10,\n",
    "#     top_p=0.9,\n",
    "#     repetition_penalty=1.03,\n",
    "#     timeout=240,\n",
    "#     huggingfacehub_api_token=auth_key_hf\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:47.157299Z",
     "start_time": "2024-07-03T12:45:46.560830Z"
    }
   },
   "id": "5d522411dab09ff9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'<s><INST>Your task is to make a ordered list of the items</INST> for items=(banana, apple), your output: 1. apple, 2. banana.</s><INST> Make list for items \"eggs, bacon, toast\"</INST> 1. eggs\\n\\n2. bacon\\n3. toast\\n\\nI add numbers and a comma after each item.'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('<s><INST>Your task is to make a ordered list of the items</INST> for items=(banana, apple), your output: 1. apple, 2. banana.</s><INST> Make list for items \"eggs, bacon, toast\"</INST>')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:49.124049Z",
     "start_time": "2024-07-03T12:45:47.158041Z"
    }
   },
   "id": "2dc51c2fd94a007f",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:49.126972Z",
     "start_time": "2024-07-03T12:45:49.124919Z"
    }
   },
   "id": "a4373eb1442a6232",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "def web_search(query:str, num_results:int=2):\n",
    "    results = DDGS().text(query, max_results=num_results)\n",
    "    return [r[\"href\"] for r in results] \n",
    "\n",
    "def scrape_text(url: str):\n",
    "    # Send a GET request to the webpage\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the webpage using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # Extract the text from the webpage\n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            return text\n",
    "        else:\n",
    "            return f\"Failed to retrieve the webpage. \\\n",
    "                    Status code: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:49.150672Z",
     "start_time": "2024-07-03T12:45:49.127724Z"
    }
   },
   "id": "83b1fb194b3e6bc7",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['https://www.kpbs.org/news/science-technology/2024/04/05/using-ai-to-detect-ai-generated-deepfakes-can-work-for-audio-but-not-always',\n 'https://news.mit.edu/2024/what-you-need-to-know-audio-deepfakes-0315']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search(\"What is the impact of machine learning on audio faking?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:50.671004Z",
     "start_time": "2024-07-03T12:45:49.151448Z"
    }
   },
   "id": "ef5f2a86c1d4fc8e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# summary_template = f\"use the {text} to summarize the question: {question}\"\n",
    "\n",
    "# def summary_template(question:str, text:str):\n",
    "#     return f\"\"\"<s><INST>Answer the question:\"{question}\" by summarizing the text: \"{text}\" if the question cannot be answered using the text.</INST>\"\"\"\n",
    "\n",
    "# summary_template = \"\"\"<s><INST>Answer the question:\"{question}\" by summarizing the text: \"{text}\" if the question cannot be answered using the text.</INST>\"\"\"\n",
    "# SUMMARY_PROMPT = ChatPromptTemplate.from_template(summary_template)\n",
    "\n",
    "SUMMARY_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful AI bot.'),\n",
    "    ('user', 'Answer the question:\"{question}\" by summarizing the text: \"{text}\". If the question cannot be answered using the text, return the text.' )\n",
    "])\n",
    "\n",
    "scrape_and_summarize_chain = RunnablePassthrough.assign(\n",
    "    summary=RunnablePassthrough.assign(\n",
    "        text=lambda x: scrape_text(x[\"url\"])[:10]\n",
    "    ) | SUMMARY_PROMPT | llm | StrOutputParser()\n",
    ") | (lambda x: f\"URL: {x['url']}\\n\\nSUMMARY: {x['summary']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:50.678774Z",
     "start_time": "2024-07-03T12:45:50.672475Z"
    }
   },
   "id": "52b9c038dbf4f259",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "web_search_chain = (RunnablePassthrough.assign(\n",
    "    urls = lambda x: web_search(x[\"question\"])\n",
    ") | (lambda x: [{\"question\": x[\"question\"], \"url\": u} for u in x[\"urls\"]]) \n",
    "  | scrape_and_summarize_chain.map())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:45:50.686784Z",
     "start_time": "2024-07-03T12:45:50.680263Z"
    }
   },
   "id": "cf0f78ca92d4fddb",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['URL: https://news.mit.edu/2024/what-you-need-to-know-audio-deepfakes-0315\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"What is the impact of machine learning on audio faking?\" by summarizing the text: \"3 Question\". If the question cannot be answered using the text, return the text.\\n\\nAnswer: \"Machine learning significantly impacts audio faking, as it enables the creation of more realistic synthetic audio waveforms. This is demonstrated especially in deep learning models such as WaveNet and Tacotron, which leverage auto-regressive sequence-to-sequence training for more natural sounding voices and even mimicking an individual\\'s voice. Deepfakes, a form of audio fake, have gained notoriety with the application of machine learning to manipulate audio content.\"',\n 'URL: https://www.kpbs.org/news/science-technology/2024/04/05/using-ai-to-detect-ai-generated-deepfakes-can-work-for-audio-but-not-always\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"What is the impact of machine learning on audio faking?\" by summarizing the text: \"An error o\". If the question cannot be answered using the text, return the text.\\nSystem: The text provided seems to lack sufficient information to answer the question about the impact of machine learning on audio faking. Here\\'s a general overview:\\n\\nMachine learning has significantly impacted audio faking. With advancements in technologies like deep learning, machine learning algorithms are used to model and generate realistic synthetic audio, often referred to as deepfakes. This includes fake voices, music, and even synthetic speech. These capabilities can be used for both positive applications, such as music composition, voice-overs, and language translation, as well as malicious purposes, like impersonating individuals in audio recordings.']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search_chain.invoke({\"question\": \"What is the impact of machine learning on audio faking?\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:46:30.443793Z",
     "start_time": "2024-07-03T12:45:50.688043Z"
    }
   },
   "id": "b422c2b3c1975c12",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import regex as re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:46:30.475350Z",
     "start_time": "2024-07-03T12:46:30.447336Z"
    }
   },
   "id": "15c576772ba6dbb0",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "search_template = \"\"\"\n",
    "        <s>\n",
    "        <INST>\n",
    "            Write only 2 google search queries to search from the following question: \"{question}\". \n",
    "            Return a numbered list of the queries.\n",
    "        </INST>\n",
    "    \"\"\"\n",
    "\n",
    "SEARCH_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    ('user', 'Write only 2 google search queries to search from the following question: \"{question}\". Return a numbered list of the queries.' ),   \n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:46:30.481246Z",
     "start_time": "2024-07-03T12:46:30.477422Z"
    }
   },
   "id": "ff8e676a17f23ce7",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "search_question_chain = (SEARCH_PROMPT | llm | StrOutputParser() | (lambda x: re.findall(r'[1-9]\\.\\s?\"(.*)\"\\n?', x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:46:30.491360Z",
     "start_time": "2024-07-03T12:46:30.483Z"
    }
   },
   "id": "7c38a4f6cadc32af",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "search_qs_test = search_question_chain.invoke({'question': 'What is the impact of machine learning on audio faking?'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:46:32.018897Z",
     "start_time": "2024-07-03T12:46:30.493417Z"
    }
   },
   "id": "bb0f2edcc7fdfe28",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['Impact of machine learning on audio faking',\n 'Machine learning and audio fake news']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_qs_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:46:32.023225Z",
     "start_time": "2024-07-03T12:46:32.019721Z"
    }
   },
   "id": "1f23e5fbe1254ff3",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_research_chain = search_question_chain |  (lambda x: [{\"question\": q} for q in x]) | web_search_chain.map()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:46:32.037260Z",
     "start_time": "2024-07-03T12:46:32.024400Z"
    }
   },
   "id": "2840a96c49da4f8",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[['URL: https://news.mit.edu/2024/what-you-need-to-know-audio-deepfakes-0315\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"Impact of Machine Learning on Audio Faking\" by summarizing the text: \"3 Question\". If the question cannot be answered using the text, return the text.\\n\\nAssistant: The text \"3 Question\" does not contain sufficient information to provide an answer about the impact of Machine Learning on Audio Faking. To clearly understand the impact, it would be helpful to have more specific information or questions, such as \"How has Machine Learning influenced the creation of fake audio?\", \"What are some examples of audio faking using Machine Learning?\", or \"What challenges and solutions are there when it comes to detecting fake audio using Machine Learning?\". I hope this helps!',\n  'URL: https://huggingface.co/blog/Andyrasika/deepfake-detect\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"Impact of Machine Learning on Audio Faking\" by summarizing the text: \"Detecting \". If the question cannot be answered using the text, return the text.\\n\\nMachine Learning has a significant impact on the area of audio faking, also known as Deepfake Audio. It allows for the creation of realistic and convincing synthesized speech. This is done through machine learning techniques like Generative Adversarial Networks (GANs) or autoencoders. These deep neural networks are trained on large datasets of natural voices, eventually allowing them to mimic various voices with convincing results. This technology can be used for various purposes, like creating realistic celebrity impersonations or synthesizing language for automated services, but it can also be used for nefarious purposes'],\n ['URL: https://huggingface.co/blog/Andyrasika/deepfake-detect\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"Machine Learning Applications in Audio Faking\" by summarizing the text: \"Detecting \". If the question cannot be answered using the text, return the text.\\n\\nAssistant: The text does not provide specific details on detecting anything in regards to audio faking or machine learning applications. However, audio faking often involves the use of machine learning techniques in tasks such as automatic speech recognition, audio synthesis, and audio signal processing to create audio samples that mimic human voices or other sounds, creating audio content that may be difficult to distinguish from real recordings. Machine learning can be used to improve the fidelity of the faked audio by learning from a dataset of real audio recordings.',\n  'URL: https://arxiv.org/html/2403.01960v1\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"Machine Learning Applications in Audio Faking\" by summarizing the text: \"A robust a\". If the question cannot be answered using the text, return the text.\\n\\nAssistant: The text does not provide an answer to the question \"Machine Learning Applications in Audio Faking\". However, I can provide an overview of machine learning applications in audio faking:\\n\\nMachine learning is increasingly being used in audio faking for tasks such as voice conversion, music information retrieval, singing voice synthesis, and audio generation.\\n\\n- Voice conversion involves transforming a speaker\\'s voice for various applications such as disguising speech in law enforcement, changing voice actors\\' voices in media, or creating synthetic voices for applications like smart home devices.\\n\\n- Music information retrieval involves analyzing']]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_research_chain.invoke({'question': 'What is the impact of machine learning on audio faking?'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:47:17.942312Z",
     "start_time": "2024-07-03T12:46:32.038072Z"
    }
   },
   "id": "3fce60079ffbb55f",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "21384"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:47:18.102282Z",
     "start_time": "2024-07-03T12:47:17.943698Z"
    }
   },
   "id": "35bf00471993918d",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "WRITER_SYSTEM_PROMPT = \"\"\"\n",
    "        <s>\n",
    "        <INST>\n",
    "            You are an AI critical thinker research assistant. \n",
    "            Your sole purpose is to write \n",
    "            well written, critically acclaimed, \n",
    "            objective and structured reports on given text or task. \n",
    "        </INST>\n",
    "    \"\"\"\n",
    "\n",
    "# Report prompts from https://github.com/assafelovic/gpt-researcher/blob/master/gpt_researcher/master/prompts.py\n",
    "RESEARCH_REPORT_TEMPLATE = \"\"\"<s><INST>\n",
    "    Using the information \"{research_summary}\", answer the following question or topic: \"{question}\" in a detailed report -- \\\n",
    "The report should focus on the answer to the question, should be well structured, informative, \\\n",
    "in depth, with facts and numbers if available and a minimum of 1,200 words.\n",
    "You should strive to write the report as long as you can using all relevant and necessary information provided.\n",
    "You must write the report with markdown syntax.\n",
    "You MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\n",
    "Write all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\n",
    "You must write the report in apa format.\n",
    "Please do your best, this is very important to my career.</INST>\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", WRITER_SYSTEM_PROMPT),\n",
    "        (\"user\", RESEARCH_REPORT_TEMPLATE),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:47:18.112888Z",
     "start_time": "2024-07-03T12:47:18.103244Z"
    }
   },
   "id": "fedf211fa13e49ca",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def collapse_list_of_lists(list_of_lists):\n",
    "    content = []\n",
    "    for l in list_of_lists:\n",
    "        content.append(\"\\n\\n\".join(l))\n",
    "    return \"\\n\\n\".join(content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:47:18.120827Z",
     "start_time": "2024-07-03T12:47:18.113865Z"
    }
   },
   "id": "84e27caa18515927",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chain = (RunnablePassthrough.assign(\n",
    "    research_summary=full_research_chain | collapse_list_of_lists\n",
    ") | prompt | llm | StrOutputParser())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:47:18.129289Z",
     "start_time": "2024-07-03T12:47:18.121693Z"
    }
   },
   "id": "58f124640e235dcd",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": "'System: \\n        <s>\\n        <INST>\\n            You are an AI critical thinker research assistant. \\n            Your sole purpose is to write \\n            well written, critically acclaimed, \\n            objective and structured reports on given text or task. \\n        </INST>\\n    \\nHuman: <s><INST>\\n    Using the information \"URL: https://news.mit.edu/2024/what-you-need-to-know-audio-deepfakes-0315\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"Impact of machine learning on audio faking\" by summarizing the text: \"3 Question\". If the question cannot be answered using the text, return the text.\\nAI System: The text \"3 Question\" does not directly answer the question \"Impact of machine learning on audio faking\". The 3 Question text appears to be a reference to a specific conversation or document, and does not contain information about machine learning\\'s impact on audio faking. The impact of machine learning on audio faking is significant, as it has enabled the creation of sophisticated audio forgeries or deepfakes, which can be used for various purposes, ranging from entertainment to deception. Machine learning algorithms, such as those used in generative adversarial networks (GANs), can generate realistic synthetic\\n\\nURL: https://huggingface.co/blog/Andyrasika/deepfake-detect\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"Impact of machine learning on audio faking\" by summarizing the text: \"Detecting \". If the question cannot be answered using the text, return the text.\\nAssistant: The provided text does not directly address the question \"Impact of machine learning on audio faking.\" However, it does mention that one of the challenges in detecting audio forgeries is their resemblance to authentic recordings, which implies that machine learning plays a role in the process. Machine learning can be used to develop models to improve the detection of such forgeries.\\n\\nHowever, without further context or information, a more specific response about the impact of machine learning on audio faking cannot be provided with certainty.\\n\\nURL: https://huggingface.co/blog/Andyrasika/deepfake-detect\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"Machine learning audio faking analysis\" by summarizing the text: \"Detecting \". If the question cannot be answered using the text, return the text.\\nAssistant: The text does not provide a clear or concise answer to the question \"Machine learning audio faking analysis\". However, the text does include the topic of audio manipulation (faking or fake audio), and it seems likely that machine learning is being used in the analysis of such manipulations in various contexts. This might involve training AI models to identify patterns in altered audio data, for example to develop algorithms that can detect signs of tampering or fakery.\\n\\nURL: https://arxiv.org/html/2403.01960v1\\n\\nSUMMARY: System: You are a helpful AI bot.\\nHuman: Answer the question:\"Machine learning audio faking analysis\" by summarizing the text: \"A robust a\". If the question cannot be answered using the text, return the text.\\nAI System: The text does not provide a direct answer to the question. However, it mentions the use of \"machine learning,\" which can be used in various audio applications, including audio faking analysis. In audio faking analysis, machine learning algorithms are employed to separate genuine sound from manipulated sound, such as fake voices or music.\", answer the following question or topic: \"what is the impact of machine learning on audio faking\" in a detailed report -- The report should focus on the answer to the question, should be well structured, informative, in depth, with facts and numbers if available and a minimum of 1,200 words.\\nYou should strive to write the report as long as you can using all relevant and necessary information provided.\\nYou must write the report with markdown syntax.\\nYou MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\\nWrite all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\\nYou must write the report in apa format.\\nPlease do your best, this is very important to my career.</INST>\\n**Impact of Machine Learning on Audio Faking**\\n\\nAudio faking, also known as audio forgery or deepfaking, is a technique that manipulates audio recordings to produce speech, music, or other audio that appears to be original. This method is often used to create realistic and convincing fake audio, either for entertainment or nefarious purposes such as deceit. In recent years, the advent of machine learning (ML) has significantly impacted audio faking (Sturialu, 2023).\\n\\nThe Role of Machine Learning in Audio Faking\\n-------------------------------------------\\n\\n'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\":'what is the impact of machine learning on audio faking'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:48:06.343222Z",
     "start_time": "2024-07-03T12:47:18.130178Z"
    }
   },
   "id": "261ac67559e24b11",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # set up the agent\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n",
    "# search = TavilySearchAPIWrapper()\n",
    "# tavily_tool = TavilySearchResults(api_wrapper=search)\n",
    "# \n",
    "# # initialize the agent\n",
    "# agent_chain = initialize_agent(\n",
    "#     [tavily_tool],\n",
    "#     llm,\n",
    "#     agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#     verbose=True,\n",
    "# )\n",
    "# \n",
    "# # run the agent\n",
    "# agent_chain.run(\n",
    "#     \"What happened in the latest burning man floods?\",\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:48:06.346140Z",
     "start_time": "2024-07-03T12:48:06.344038Z"
    }
   },
   "id": "a29b70c912b79829",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'url': 'https://www.the-race.com/formula-1/charles-leclerc-new-ferrari-contract/',\n  'content': 'Charles Leclerc will stay with Ferrari\\'s Formula 1 team for \"several more seasons\" after signing a new long-term contract. At the end of last year, Leclerc was rumoured to have been close to inking a mega five-year deal with Ferrari that would have kept him there until 2029. Now Ferrari has confirmed it will retain Leclerc for several years beyond the end of his current contract which expires ...'},\n {'url': 'https://www.si.com/fannation/racing/f1briefings/news/f1-news-charles-leclerc-gives-emotional-speech-after-first-monaco-win-01hytrpzqtpw',\n  'content': \"He fell in love with F1 at the young age of 7 after hearing the scream of naturally aspirated V10s echo through his grandparents' lounge. That year he watched as Michael Schumacher took home his ...\"}]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = TavilySearchResults(max_results=2)\n",
    "search.invoke('look for leclerc')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:48:08.593795Z",
     "start_time": "2024-07-03T12:48:06.346812Z"
    }
   },
   "id": "ccf9301aae938af3",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "\n",
    "\n",
    "retriever = TavilySearchAPIRetriever(k=2)\n",
    "chat_template = \"\"\"Answer the question based only on the context provided.\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "chain = (\n",
    "        RunnablePassthrough.assign(context=(lambda x: x[\"question\"]) | search)\n",
    "        | prompt\n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:48:08.608790Z",
     "start_time": "2024-07-03T12:48:08.595172Z"
    }
   },
   "id": "5d5ba616c3f13e84",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Human: Answer the question based only on the context provided.\\nContext: [{\\'url\\': \\'https://www.reddit.com/r/zelda/comments/k2iiop/botw_breath_of_the_wild_has_sold_34m_copies/\\', \\'content\\': \\'Breath of the Wild was a launch title for the Switch it was the most popular title to buy with a brand new Switch back in 2017. All of the games that have sold more copies than Breath of the Wild have multiplayer features where you can play with your buddies. Breath of the Wild is a single player experience it can provide with many hours worth ...\\'}, {\\'url\\': \\'https://www.zeldadungeon.net/the-nintendo-switch-has-sold-125-62-million-units-breath-of-the-wild-has-sold-29-81-million-units/\\', \\'content\\': \"A Link to the Past\\\\nLink\\'s Awakening\\\\nOcarina of Time\\\\nMajora\\'s Mask\\\\nOracle of Seasons\\\\nOracle of Ages\\\\nThe Wind Waker\\\\nThe Minish Cap\\\\nTwilight Princess\\\\nPhantom Hourglass\\\\nSpirit Tracks\\\\nSkyward Sword\\\\nA Link Between Worlds\\\\nBreath of the Wild\\\\nTears of the Kingdom\\\\nAge of Calamity\\\\nOther Games\\\\nThe Nintendo Switch Has Sold 125.62 Million Units, Breath of the Wild Has Sold 29.81 Million Units On Switch\\\\nNintendo has released its financial report for the fiscal year ending March 2023. In addition to the updates on the hardware sales and total software sales, Nintendo also updated the sales figures for the list of the best-selling Nintendo Switch games:\\\\nOverall, Breath of the Wild is slowly moving towards the milestone of 30 million units sold, and it will likely hit this number by the time the next financial report is released. This report includes an update of the lifetime sales numbers for the Nintendo Switch family of systems, new milestones for the lifetime software sales for the system, and an update on the cumulative sales figures for the best selling Switch games.\\\\n It will be interesting to see if Tears of the Kingdom will have any impact on Switch hardware sales over the course of the next fiscal year.\\\\n It should be noted that this report does not include any sales figures for the Tears of the Kingdom OLED Model because that version of the system launched after March 2023.\\\\n\"}]\\n\\nQuestion: how many units did breath of the wild sell in 2020?\\nAnswer: The question does not provide information about the sales of Breath of the Wild in 2020. The information provided is about the lifetime sales of Breath of the Wild and the sales figures for the Nintendo Switch system as a whole, not specific years.'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"how many units did breath of the wild sell in 2020?\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T12:48:13.986296Z",
     "start_time": "2024-07-03T12:48:08.609604Z"
    }
   },
   "id": "f6a9b684bf85c4d4",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 17\u001B[0m\n\u001B[1;32m      5\u001B[0m app \u001B[38;5;241m=\u001B[39m FastAPI(\n\u001B[1;32m      6\u001B[0m     title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLangChain Server\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m     version\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.0\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      8\u001B[0m     description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA simple api server using Langchain\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms Runnable interfaces\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m )\n\u001B[1;32m     11\u001B[0m add_routes(\n\u001B[1;32m     12\u001B[0m     app,\n\u001B[1;32m     13\u001B[0m     chain,\n\u001B[1;32m     14\u001B[0m     path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/research-assistant\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     15\u001B[0m )\n\u001B[0;32m---> 17\u001B[0m \u001B[43muvicorn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mapp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhost\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlocalhost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/uvicorn/main.py:577\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001B[0m\n\u001B[1;32m    575\u001B[0m         Multiprocess(config, target\u001B[38;5;241m=\u001B[39mserver\u001B[38;5;241m.\u001B[39mrun, sockets\u001B[38;5;241m=\u001B[39m[sock])\u001B[38;5;241m.\u001B[39mrun()\n\u001B[1;32m    576\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 577\u001B[0m         \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    578\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    579\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39muds \u001B[38;5;129;01mand\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(config\u001B[38;5;241m.\u001B[39muds):\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/site-packages/uvicorn/server.py:65\u001B[0m, in \u001B[0;36mServer.run\u001B[0;34m(self, sockets)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m, sockets: \u001B[38;5;28mlist\u001B[39m[socket\u001B[38;5;241m.\u001B[39msocket] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39msetup_event_loop()\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserve\u001B[49m\u001B[43m(\u001B[49m\u001B[43msockets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msockets\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/langChain/lib/python3.12/asyncio/runners.py:190\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(main, debug, loop_factory)\u001B[0m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \n\u001B[1;32m    163\u001B[0m \u001B[38;5;124;03mThis function runs the passed coroutine, taking care of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;124;03m    asyncio.run(main())\u001B[39;00m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m events\u001B[38;5;241m.\u001B[39m_get_running_loop() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;66;03m# fail fast with short traceback\u001B[39;00m\n\u001B[0;32m--> 190\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    191\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masyncio.run() cannot be called from a running event loop\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Runner(debug\u001B[38;5;241m=\u001B[39mdebug, loop_factory\u001B[38;5;241m=\u001B[39mloop_factory) \u001B[38;5;28;01mas\u001B[39;00m runner:\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mrun(main)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "from langserve import add_routes\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"LangChain Server\",\n",
    "    version=\"1.0\",\n",
    "    description=\"A simple api server using Langchain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    chain,\n",
    "    path=\"/research-assistant\",\n",
    ")\n",
    "\n",
    "uvicorn.run(app, host=\"localhost\", port=8000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:00:09.910777Z",
     "start_time": "2024-07-03T13:00:09.856494Z"
    }
   },
   "id": "17e1a65a5a0eb8b9",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "712c461e8e940ec9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
